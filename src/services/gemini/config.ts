import { GoogleGenerativeAI } from '@google/generative-ai';

// Láº¥y API key tá»« biáº¿n mÃ´i trÆ°á»ng
const apiKey = process.env.NEXT_PUBLIC_GEMINI_API_KEY || '';

// Khá»Ÿi táº¡o Google Generative AI vá»›i API key
export const genAI = new GoogleGenerativeAI(apiKey);

// Cáº¥u hÃ¬nh model Gemini
export const geminiConfig = {
  model: process.env.NEXT_PUBLIC_GEMINI_MODEL || 'gemini-1.5-flash',
  maxOutputTokens: 1000,
  temperature: 0.9, // TÄƒng temperature Ä‘á»ƒ AI sÃ¡ng táº¡o hÆ¡n
  topP: 0.95,
  topK: 40,
};

/**
 * Táº¡o instance cá»§a model
 * @returns Model instance
 */
export const getGeminiModel = () => {
  return genAI.getGenerativeModel(geminiConfig);
};

/**
 * Gá»i API Gemini Ä‘á»ƒ táº¡o pháº£n há»“i
 * @param prompt Prompt chÃ­nh cáº§n gá»­i Ä‘áº¿n API
 * @param chatHistory Lá»‹ch sá»­ chat Ä‘á»ƒ cung cáº¥p ngá»¯ cáº£nh
 * @returns Pháº£n há»“i tá»« API
 */
export const generateGeminiResponse = async (
  prompt: string,
  _chatHistory: Array<{ role: 'user' | 'model'; content: string }> = [],
): Promise<string> => {
  try {
    if (!apiKey) {
      console.warn('Missing Gemini API key. Using fallback responses.');
      throw new Error('Missing API key');
    }

    // Chá»‰ log trong mÃ´i trÆ°á»ng development
    if (process.env.NODE_ENV === 'development') {
      console.log(
        'Calling Gemini API with prompt:',
        prompt.substring(0, 100) + '...',
      );
    }

<<<<<<< HEAD
=======
    console.log("Calling Gemini API with chat history length:", chatHistory.length);
    
>>>>>>> origin/main
    const model = getGeminiModel();

    // Táº¡o chat session vá»›i lá»‹ch sá»­ cuá»™c há»™i thoáº¡i
    let result;

    try {
      // Sá»­ dá»¥ng startChat Ä‘á»ƒ duy trÃ¬ ngá»¯ cáº£nh trÃ² chuyá»‡n
      const chat = model.startChat({
        history: chatHistory.map(msg => ({
          role: msg.role === 'user' ? 'user' : 'model',
          parts: [{ text: msg.content }]
        })),
        generationConfig: {
          maxOutputTokens: geminiConfig.maxOutputTokens,
          temperature: geminiConfig.temperature,
          topP: geminiConfig.topP,
          topK: geminiConfig.topK,
        },
      });
      
      // Gá»­i tin nháº¯n má»›i vÃ  nháº­n pháº£n há»“i
      result = await chat.sendMessage(prompt);
    } catch (error) {
<<<<<<< HEAD
      // Chá»‰ log trong mÃ´i trÆ°á»ng development
      if (process.env.NODE_ENV === 'development') {
        console.error('Error generating content from AI:', error);
      }
      // KhÃ´ng truyá»n lá»—i gá»‘c vÃ¬ cÃ³ thá»ƒ chá»©a thÃ´ng tin nháº¡y cáº£m
      throw new Error('Failed to generate AI response');
=======
      console.error("Error using chat API, falling back to direct generation");
      
      try {
        // Fallback: Táº¡o prompt bao gá»“m lá»‹ch sá»­ trÃ² chuyá»‡n
        let fullPrompt = "";
        
        // ThÃªm lá»‹ch sá»­ trÃ² chuyá»‡n vÃ o prompt
        if (chatHistory.length > 0) {
          fullPrompt += "Lá»‹ch sá»­ trÃ² chuyá»‡n:\n\n";
          chatHistory.forEach(msg => {
            const role = msg.role === 'user' ? 'NgÆ°á»i dÃ¹ng' : 'AI';
            fullPrompt += `${role}: ${msg.content}\n\n`;
          });
          fullPrompt += "Tin nháº¯n hiá»‡n táº¡i:\n\n";
        }
        
        fullPrompt += prompt;
        
        // Sá»­ dá»¥ng generateContent vá»›i prompt Ä‘áº§y Ä‘á»§
        result = await model.generateContent(fullPrompt);
      } catch (fallbackError) {
        console.error("Error with fallback generation");
        throw new Error("Failed to generate AI response");
      }
>>>>>>> origin/main
    }

    const response = await result.response;
    const text = response.text();

    return text;
  } catch (error) {
<<<<<<< HEAD
    // Chá»‰ log trong mÃ´i trÆ°á»ng development
    if (process.env.NODE_ENV === 'development') {
      console.error('Error generating Gemini response:', error);
    }
    // KhÃ´ng truyá»n lá»—i gá»‘c vÃ¬ cÃ³ thá»ƒ chá»©a thÃ´ng tin nháº¡y cáº£m
    throw new Error('Failed to generate AI response');
=======
    console.error("Error generating Gemini response");
    throw new Error("Failed to generate AI response");
>>>>>>> origin/main
  }
};

/**
 * Táº¡o pháº£n há»“i local khi khÃ´ng cÃ³ API key hoáº·c API gáº·p lá»—i
 * @param userMessage Tin nháº¯n cá»§a ngÆ°á»i dÃ¹ng
 * @returns Pháº£n há»“i local
 */
export const generateLocalAIResponse = (_userMessage: string): string => {
  const responses = [
    'ğŸ”Œ Hiá»‡n táº¡i tÃ´i khÃ´ng thá»ƒ káº¿t ná»‘i tá»›i mÃ¡y chá»§ AI. Trong lÃºc chá» Ä‘á»£i, báº¡n cÃ³ thá»ƒ:\n\nğŸ“š Ã”n táº­p flashcards Ä‘Ã£ táº¡o\nâ° Sá»­ dá»¥ng Pomodoro timer Ä‘á»ƒ há»c táº­p\nâœ… HoÃ n thÃ nh thÃ³i quen há»c táº­p hÃ ng ngÃ y\n\nğŸ”„ Vui lÃ²ng kiá»ƒm tra káº¿t ná»‘i internet vÃ  thá»­ láº¡i sau!',

    'ğŸ’¡ TÃ´i Ä‘ang gáº·p sá»± cá»‘ ká»¹ thuáº­t táº¡m thá»i. ÄÃ¢y lÃ  má»™t sá»‘ gá»£i Ã½ há»c tiáº¿ng Anh báº¡n cÃ³ thá»ƒ thá»­:\n\nğŸ§ Nghe podcast tiáº¿ng Anh 15-20 phÃºt/ngÃ y\nğŸ“– Äá»c tin tá»©c trÃªn BBC Learning English\nâœï¸ Viáº¿t nháº­t kÃ½ báº±ng tiáº¿ng Anh\nğŸ—£ï¸ NÃ³i chuyá»‡n vá»›i báº£n thÃ¢n báº±ng tiáº¿ng Anh\n\nâš¡ HÃ£y thá»­ láº¡i sau vÃ i phÃºt nhÃ©!',

    'ğŸš§ ÄÆ°á»ng truyá»n tá»›i AI server Ä‘ang Ä‘Æ°á»£c báº£o trÃ¬. Trong khi chá» Ä‘á»£i:\n\nğŸ“± HÃ£y thá»­ cÃ¡c chá»©c nÄƒng khÃ¡c trong app\nğŸ“ Táº¡o flashcards thá»§ cÃ´ng\nâ²ï¸ Luyá»‡n táº­p vá»›i Pomodoro timer\nğŸ“Š Kiá»ƒm tra tiáº¿n Ä‘á»™ há»c táº­p cá»§a báº¡n\n\nğŸ”„ TÃ´i sáº½ quay láº¡i sá»›m thÃ´i!',
  ];

  return responses[Math.floor(Math.random() * responses.length)];
};
